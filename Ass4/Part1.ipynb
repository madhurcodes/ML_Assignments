{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:22.477589Z",
     "start_time": "2018-04-20T09:48:22.141332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:22.496151Z",
     "start_time": "2018-04-20T09:48:22.488953Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trfiles = os.listdir(\"./train/\")\n",
    "cats = [c.split(\".\")[0] for c in trfiles]\n",
    "cid_to_cat = {}\n",
    "cat_to_cid = {}\n",
    "for idx,cat in zip(range(len(cats)),cats):\n",
    "    cat_to_cid[cat] = idx\n",
    "    cid_to_cat[idx] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:25.875562Z",
     "start_time": "2018-04-20T09:48:22.589615Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_data = None\n",
    "for file in trfiles:\n",
    "    d = np.load(\"train/\"+file)\n",
    "    myidx = cat_to_cid[file.split(\".\")[0]]\n",
    "    idarr = myidx + np.zeros(d.shape[0])\n",
    "    d = np.concatenate((d,idarr[:,np.newaxis]),axis=1)\n",
    "    if known_data is None:\n",
    "        known_data = d\n",
    "    else:\n",
    "        known_data = np.concatenate((known_data,d),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:26.255741Z",
     "start_time": "2018-04-20T09:48:25.894035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(known_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:26.277492Z",
     "start_time": "2018-04-20T09:48:26.271985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = known_data[:int(0.8*known_data.shape[0]),:]\n",
    "val_data = known_data[int(0.8*known_data.shape[0]):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:27.623471Z",
     "start_time": "2018-04-20T09:48:26.297040Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_data[:,:784]\n",
    "train_y = train_data[:,784].astype(int)\n",
    "val_x = val_data[:,:784]\n",
    "val_y = val_data[:,784].astype(int)\n",
    "train_x = (train_x - train_x.mean(axis=0) ) / train_x.std(axis=0) \n",
    "val_x = (val_x - val_x.mean(axis=0) ) / val_x.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_x = known_data[:,:784]\n",
    "full_y = known_data[:,784].astype(int)\n",
    "full_x = (full_x - full_x.mean(axis=0) ) / full_x.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:27.648607Z",
     "start_time": "2018-04-20T09:48:27.643899Z"
    }
   },
   "outputs": [],
   "source": [
    "full_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.cluster import KMeans \n",
    "from sklearn.cluster import AgglomerativeClustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=20,n_init=40,precompute_distances=True,n_jobs=-1,max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clus_to_pred_dic = {}\n",
    "for p in range(train_y.shape[0]):\n",
    "    clus = km.labels_[p]\n",
    "    truel = train_y[p]\n",
    "    if clus not in clus_to_pred_dic.keys():\n",
    "        clus_to_pred_dic[clus] = {}\n",
    "    if truel not in clus_to_pred_dic[clus].keys():\n",
    "        clus_to_pred_dic[clus][truel] = 0\n",
    "    clus_to_pred_dic[clus][truel] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusid_to_cid = {}\n",
    "for clus in clus_to_pred_dic.keys():\n",
    "    clusid_to_cid[clus] = max(clus_to_pred_dic[clus],key=clus_to_pred_dic[clus].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train_c = km.predict(train_x)\n",
    "pred_val_c = km.predict(val_x)\n",
    "pred_train = []\n",
    "pred_val = []\n",
    "for g in range(pred_train_c.shape[0]):\n",
    "    pred_train.append(clusid_to_cid[pred_train_c[g]])\n",
    "for g in range(pred_val_c.shape[0]):\n",
    "    pred_val.append(clusid_to_cid[pred_val_c[g]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(train_y,pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(val_y,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for maxit in [10,20,30,40,50]:\n",
    "    km = KMeans(n_clusters=20,n_init=40,precompute_distances=True,n_jobs=-1,max_iter=50)\n",
    "    km.fit(train_x)\n",
    "    clus_to_pred_dic = {}\n",
    "    for p in range(train_y.shape[0]):\n",
    "        clus = km.labels_[p]\n",
    "        truel = train_y[p]\n",
    "        if clus not in clus_to_pred_dic.keys():\n",
    "            clus_to_pred_dic[clus] = {}\n",
    "        if truel not in clus_to_pred_dic[clus].keys():\n",
    "            clus_to_pred_dic[clus][truel] = 0\n",
    "        clus_to_pred_dic[clus][truel] += 1\n",
    "        clusid_to_cid = {}\n",
    "    for clus in clus_to_pred_dic.keys():\n",
    "        clusid_to_cid[clus] = max(clus_to_pred_dic[clus],key=clus_to_pred_dic[clus].get)\n",
    "    pred_train_c = km.predict(train_x)\n",
    "    pred_val_c = km.predict(val_x)\n",
    "    pred_train = []\n",
    "    pred_val = []\n",
    "    for g in range(pred_train_c.shape[0]):\n",
    "        pred_train.append(clusid_to_cid[pred_train_c[g]])\n",
    "    for g in range(pred_val_c.shape[0]):\n",
    "        pred_val.append(clusid_to_cid[pred_val_c[g]])\n",
    "    print(\"------------------------------\")\n",
    "    print (\"Max Iter \",maxit)\n",
    "    print (\"Train Accuracy \",sklearn.metrics.accuracy_score(train_y,pred_train))    \n",
    "    print (\"Test Accuracy \",sklearn.metrics.accuracy_score(val_y,pred_val))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:48:27.918732Z",
     "start_time": "2018-04-20T09:48:27.673699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:54:55.335725Z",
     "start_time": "2018-04-20T09:48:56.736683Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)# adjust yourself\n",
    "pca.fit(train_x)\n",
    "train_x_trans = pca.transform(train_x)\n",
    "val_x_trans = pca.transform(val_x)\n",
    "clf = LinearSVC()\n",
    "# clf = SVC()\n",
    "clf.fit(train_x_trans, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:54:55.380466Z",
     "start_time": "2018-04-20T09:54:55.362535Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(val_x_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:54:55.418716Z",
     "start_time": "2018-04-20T09:54:55.412507Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(val_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:06:17.602131Z",
     "start_time": "2018-04-20T10:06:17.585826Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(val_y,preds,labels=list(range(20)),target_names=[cid_to_cat[ii] for ii in range(20)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best - C = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)# adjust yourself\n",
    "pca.fit(train_x)\n",
    "train_x_trans = pca.transform(train_x)\n",
    "val_x_trans = pca.transform(val_x)\n",
    "# for c in [0.1,0.5,0.9,1.5,10]:\n",
    "for c in [1,2]:\n",
    "    clf = SVC(C=c,kernel=\"linear\",decision_function_shape=\"ovo\")\n",
    "    # clf = SVC()\n",
    "    clf.fit(train_x_trans, train_y)\n",
    "    preds = clf.predict(val_x_trans)\n",
    "    print(\"C value = \",c,\" Accuracy = \",sklearn.metrics.accuracy_score(val_y,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:04:42.519756Z",
     "start_time": "2018-04-20T10:04:42.506980Z"
    }
   },
   "outputs": [],
   "source": [
    "cid_to_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(422,433):\n",
    "    f = clf.predict(val_x_trans[i,:][np.newaxis,])\n",
    "    if f == val_y[i]:\n",
    "        print (\"corr \",cid_to_cat[f[0]])\n",
    "    else:\n",
    "        print(\"I - \",i,\"Predicted \",cid_to_cat[f[0]], \" but was \",cid_to_cat[val_y[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(val_x[377,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fcmodel(nn.Module):\n",
    "    def __init__(self,num_hidden=100,inp_dim=784,out_dim=20):\n",
    "        super().__init__()\n",
    "        self.lay = nn.Linear(inp_dim,num_hidden)\n",
    "        self.outl = nn.Linear(num_hidden,out_dim)\n",
    "    def forward(self,X):\n",
    "        mid = F.softmax(self.lay(X),dim=1)\n",
    "        return F.log_softmax(self.outl(mid),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "criterion = nn.NLLLoss()\n",
    "mod = fcmodel(num_hidden=900)\n",
    "if CUDA:\n",
    "    mod.cuda()\n",
    "optimizer = optim.Adam(mod.parameters(), lr=0.001)\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_prev = 10000\n",
    "for epoch in range(800):\n",
    "    total_loss = 0\n",
    "    for i in range(int(train_x.shape[0]/BATCH_SIZE)):\n",
    "        X_B = train_x[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "        Y_B = train_y[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        if CUDA:\n",
    "            X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "            Y_P = Variable(torch.LongTensor(Y_B)).cuda()\n",
    "        else:\n",
    "            X_P = Variable(X_B)\n",
    "            Y_P = Variable(Y_B)\n",
    "        bout = mod.forward(X_P)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(bout, Y_P)\n",
    "        loss.backward()\n",
    "        total_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if i%600 == 0:\n",
    "            print(\"Epoch \",epoch,\" Iter - \",i, \"Loss \",loss.data[0])\n",
    "    if total_loss > total_loss_prev:\n",
    "        break\n",
    "    else:\n",
    "        total_loss_prev = total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvx,vvy = val_x,val_y\n",
    "# vvx,vvy = train_x,train_y\n",
    "inp = Variable(torch.Tensor(vvx)).cuda()\n",
    "outs = mod.forward(inp)\n",
    "_, predicted = torch.max(outs.data, 1)\n",
    "tem = predicted.cpu().numpy()\n",
    "print(sklearn.metrics.accuracy_score(vvy,tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(val_y,tem,labels=list(range(20)),target_names=[cid_to_cat[ii] for ii in range(20)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_stop = 0\n",
    "for nh in [10,50,100,250,1000]:\n",
    "    CUDA = True\n",
    "    criterion = nn.NLLLoss()\n",
    "    mod = fcmodel(num_hidden=nh)\n",
    "    if CUDA:\n",
    "        mod.cuda()\n",
    "    optimizer = optim.Adam(mod.parameters(), lr=0.01)\n",
    "    BATCH_SIZE = 200\n",
    "    total_loss_prev = 10000\n",
    "    term = False\n",
    "    for epoch in range(400):\n",
    "        total_loss = 0\n",
    "        for i in range(int(train_x.shape[0]/BATCH_SIZE)):\n",
    "            X_B = train_x[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "            Y_B = train_y[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "            if CUDA:\n",
    "                X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "                Y_P = Variable(torch.LongTensor(Y_B)).cuda()\n",
    "            else:\n",
    "                X_P = Variable(X_B)\n",
    "                Y_P = Variable(Y_B)\n",
    "            bout = mod.forward(X_P)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(bout, Y_P)\n",
    "            loss.backward()\n",
    "            total_loss += loss.data[0]\n",
    "            optimizer.step()\n",
    "#             if i%600 == 0:\n",
    "#                 print(\"Epoch \",epoch,\" Iter - \",i, \"Loss \",loss.data[0])\n",
    "#         print(\"Loss is \",total_loss)\n",
    "        if total_loss > total_loss_prev and (num_to_stop>4):\n",
    "            print(\"Terminated at epoch = \",epoch)\n",
    "            break\n",
    "        elif total_loss > total_loss_prev:\n",
    "            total_loss_prev = total_loss\n",
    "            num_to_stop +=1\n",
    "        else:\n",
    "            total_loss_prev = total_loss\n",
    "            num_to_stop = 0\n",
    "#             term = False\n",
    "    vvx,vvy = val_x,val_y\n",
    "    inp = Variable(torch.Tensor(vvx)).cuda()\n",
    "    outs = mod.forward(inp)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    tem = predicted.cpu().numpy()\n",
    "    print(\"Num Hidden =\",nh,\" Accuracy = \",sklearn.metrics.accuracy_score(vvy,tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "#  CNN One layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class onecnnmodel(nn.Module):\n",
    "    def __init__(self,num_filters=80,filter_dim=5,num_hidden=100,out_dim=20):\n",
    "        super().__init__()\n",
    "#         num = 20\n",
    "        self.conv1 = nn.Conv2d(1, num_filters, filter_dim)\n",
    "        self.inp_hw = 28 \n",
    "#         self.conv2 = nn.Conv2d(num, num, 1, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(num, num, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # conv out - self.inp_hw - filter_dim + 1\n",
    "        # max pool out  -  ((up - filter_dim) / filter_dim)+1\n",
    "        self.lay = nn.Linear(int(num_filters*(((self.inp_hw - filter_dim + 1 - 2) / 2)+1)**2),num_hidden)\n",
    "        self.outl = nn.Linear(num_hidden,out_dim)\n",
    "    def forward(self,x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs,1,28,28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(bs,-1)\n",
    "#         print(x.shape)\n",
    "#         print(\"-------------\")\n",
    "        mid = F.softmax(self.lay(x),dim=1)\n",
    "        x = 0\n",
    "        y = 0\n",
    "        return F.log_softmax(self.outl(mid),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "criterion = nn.NLLLoss()\n",
    "mod = onecnnmodel()\n",
    "if CUDA:\n",
    "    mod.cuda()\n",
    "optimizer = optim.Adam(mod.parameters(), lr=0.005)\n",
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "#     av_loss = 0\n",
    "    for i in range(int(train_x.shape[0]/BATCH_SIZE)):\n",
    "        X_B = train_x[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "        Y_B = train_y[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        if CUDA:\n",
    "            X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "            Y_P = Variable(torch.LongTensor(Y_B)).cuda()\n",
    "        else:\n",
    "            X_P = Variable(X_B)\n",
    "            Y_P = Variable(Y_B)\n",
    "        bout = mod.forward(X_P)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(bout, Y_P)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         av_loss +=  loss.data[0]\n",
    "        if i%400 == 0:\n",
    "            print(\"Epoch \",epoch,\" Iter - \",i, \"Loss \",loss.data[0])\n",
    "#             av_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vvx,vvy = val_x,val_y\n",
    "# vvx,vvy = train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vvx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(int(vvx.shape[0]/BATCH_SIZE)):\n",
    "    X_B = vvx[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "    if CUDA:\n",
    "        X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "    else:\n",
    "        X_P = Variable(X_B)\n",
    "    bout = mod.forward(X_P)\n",
    "    _, predicted = torch.max(bout.data, 1)\n",
    "    tem = list(predicted.cpu().numpy())\n",
    "    preds += tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.accuracy_score(vvy,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(vvy,preds,labels=list(range(20)),target_names=[cid_to_cat[ii] for ii in range(20)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_stop = 0\n",
    "for fil in [2,3,5,7]:\n",
    "    CUDA = True\n",
    "    criterion = nn.NLLLoss()\n",
    "    mod = onecnnmodel(fil)\n",
    "    if CUDA:\n",
    "        mod.cuda()\n",
    "    optimizer = optim.Adam(mod.parameters(), lr=0.001)\n",
    "    BATCH_SIZE = 200\n",
    "    total_loss_prev = 10000\n",
    "    term = False\n",
    "    for epoch in range(400):\n",
    "        total_loss = 0\n",
    "        for i in range(int(train_x.shape[0]/BATCH_SIZE)):\n",
    "            X_B = train_x[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "            Y_B = train_y[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "            if CUDA:\n",
    "                X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "                Y_P = Variable(torch.LongTensor(Y_B)).cuda()\n",
    "            else:\n",
    "                X_P = Variable(X_B)\n",
    "                Y_P = Variable(Y_B)\n",
    "            bout = mod.forward(X_P)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(bout, Y_P)\n",
    "            loss.backward()\n",
    "            total_loss += loss.data[0]\n",
    "            optimizer.step()\n",
    "#             if i%600 == 0:\n",
    "#                 print(\"Epoch \",epoch,\" Iter - \",i, \"Loss \",loss.data[0])\n",
    "#         print(\"Loss is \",total_loss)\n",
    "        if total_loss > total_loss_prev and (num_to_stop>4):\n",
    "            print(\"Terminated at epoch = \",epoch)\n",
    "            break\n",
    "        elif total_loss > total_loss_prev:\n",
    "            total_loss_prev = total_loss\n",
    "            num_to_stop +=1\n",
    "        else:\n",
    "            total_loss_prev = total_loss\n",
    "            num_to_stop = 0\n",
    "#             term = False\n",
    "    vvx,vvy = val_x,val_y\n",
    "    inp = Variable(torch.Tensor(vvx)).cuda()\n",
    "    outs = mod.forward(inp)\n",
    "    _, predicted = torch.max(outs.data, 1)\n",
    "    tem = predicted.cpu().numpy()\n",
    "    print(\"Num Hidden =\",nh,\" Accuracy = \",sklearn.metrics.accuracy_score(vvy,tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0e89a694e26f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m332\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(val_x[332,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## More complex model tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.autograd import Variable\n",
    "# import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class exmodel(nn.Module):\n",
    "    def __init__(self,num_hidden=10,inp_dim=784,out_dim=20):\n",
    "        super().__init__()\n",
    "#         num = 20\n",
    "#         self.conv =  nn.Conv2d(1, 1, 1)\n",
    "        self.conv1_1 = nn.Conv2d(1, 10, 2)\n",
    "        self.conv1_2 = nn.Conv2d(1, 10, 3)\n",
    "        self.conv1_3 = nn.Conv2d(1, 1, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.lay = nn.Linear(10*7*7+5*6*6+1*5*5,num_hidden)\n",
    "#         self.outl = nn.Linear(num_hidden,out_dim)\n",
    "        self.outl = nn.Linear(10*13*13+10*13*13+1*12*12,out_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs,1,28,28)\n",
    "#         x = self.pool(self.conv(x))\n",
    "#         print(x.shape)\n",
    "        x_1 = self.pool(F.relu(self.conv1_1(x)))\n",
    "        x_2 = self.pool(F.relu(self.conv1_2(x)))\n",
    "        x_3 = self.pool(F.relu(self.conv1_3(x)))\n",
    "        \n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = self.pool(x)\n",
    "#         print(x_1.shape)\n",
    "#         print(x_2.shape)\n",
    "#         print(x_3.shape)\n",
    "        x_1 = x_1.view(bs,-1)\n",
    "        x_2 = x_2.view(bs,-1)    \n",
    "        x_3 = x_3.view(bs,-1)\n",
    "    \n",
    "        x = torch.cat((x_1,x_2,x_3),dim=1)\n",
    "#         print(x.shape)\n",
    "        mid = x\n",
    "#         mid = F.softmax(self.lay(x),dim=1)\n",
    "        return F.log_softmax(self.outl(mid),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CUDA = True\n",
    "# criterion = nn.NLLLoss()\n",
    "# mod = exmodel()\n",
    "# if CUDA:\n",
    "#     mod.cuda()\n",
    "# optimizer = optim.Adam(mod.parameters(), lr=0.001)\n",
    "# BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(800):\n",
    "# #     av_loss = 0\n",
    "#     for i in range(int(train_x.shape[0]/BATCH_SIZE)):\n",
    "#         X_B = train_x[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "#         Y_B = train_y[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "#         if CUDA:\n",
    "#             X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "#             Y_P = Variable(torch.LongTensor(Y_B)).cuda()\n",
    "#         else:\n",
    "#             X_P = Variable(X_B)\n",
    "#             Y_P = Variable(Y_B)\n",
    "#         bout = mod.forward(X_P)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(bout, Y_P)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# #         av_loss +=  loss.data[0]\n",
    "#         if i%50 == 0:\n",
    "#             print(\"Epoch \",epoch,\" Iter - \",i, \"Loss \",loss.data[0])\n",
    "# #             av_loss = 0\n",
    "\n",
    "# vvx,vvy = val_x,val_y\n",
    "# # vvx,vvy = train_x,train_y\n",
    "\n",
    "# vvx.shape\n",
    "\n",
    "# preds = []\n",
    "# for i in range(int(vvx.shape[0]/BATCH_SIZE)):\n",
    "#     X_B = vvx[i*BATCH_SIZE:(i+1)*BATCH_SIZE,:]\n",
    "#     if CUDA:\n",
    "#         X_P = Variable(torch.Tensor(X_B)).cuda()\n",
    "#     else:\n",
    "#         X_P = Variable(X_B)\n",
    "#     bout = mod.forward(X_P)\n",
    "#     _, predicted = torch.max(bout.data, 1)\n",
    "#     tem = list(predicted.cpu().numpy())\n",
    "#     preds += tem\n",
    "\n",
    "# vvy.shape\n",
    "\n",
    "# print(sklearn.metrics.accuracy_score(vvy,preds))\n",
    "\n",
    "# print(sklearn.metrics.classification_report(vvy,preds,labels=list(range(20)),target_names=[cid_to_cat[ii] for ii in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:03:56.341268Z",
     "start_time": "2018-04-20T10:03:56.327047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(322,333):\n",
    "#     f = clf.predict(val_x_trans[i,:][np.newaxis,])\n",
    "#     if f == val_y[i]:\n",
    "#         print (\"corr \",cid_to_cat[f[0]])\n",
    "#     else:\n",
    "#         print(\"I - \",i,\"Predicted \",cid_to_cat[f[0]], \" but was \",cid_to_cat[val_y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T10:04:02.486697Z",
     "start_time": "2018-04-20T10:04:02.320409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(val_x[332,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-20T09:39:04.840Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print ('score', clf.score(val_x_trans, val_y))\n",
    "# print ('pred label', clf.predict(val_x_trans)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "360px",
    "left": "542px",
    "right": "255px",
    "top": "55px",
    "width": "579px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
