{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:01.667028Z",
     "start_time": "2018-04-11T08:05:01.087095Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip( x, -15, 15 )\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:04:52.766411Z",
     "start_time": "2018-04-11T08:04:52.331371Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"Implements a Fully connected neural network with sigmoid activation\n",
    "        and boolean output.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_inputs,\n",
    "                 hidden_node_list,\n",
    "                 batch_size,\n",
    "                 lr=0.1,\n",
    "                 regularization_weight=0.001,\n",
    "                 num_epochs=1):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_inputs = num_inputs\n",
    "        self.lr = lr\n",
    "        #         self.random_init_limit = 0.001\n",
    "        self.normal_std = 1\n",
    "        # (weights,biases,num_outputs)\n",
    "        self.hidden_layers = [[\n",
    "            np.random.normal(\n",
    "                scale=self.normal_std, size=(hidden_node_list[0], num_inputs)),\n",
    "            np.zeros(hidden_node_list[0]), hidden_node_list[0]\n",
    "        ]]\n",
    "        last_outputs = hidden_node_list[0]\n",
    "        for hidden_layer_dim in hidden_node_list[1:]:\n",
    "            self.hidden_layers.append([\n",
    "                np.random.normal(\n",
    "                    scale=self.normal_std,\n",
    "                    size=(hidden_layer_dim, last_outputs)),\n",
    "                np.zeros(hidden_layer_dim), hidden_layer_dim\n",
    "            ])\n",
    "            last_outputs = hidden_layer_dim\n",
    "        self.hidden_layers.append([\n",
    "            np.random.normal(scale=self.normal_std, size=(1, last_outputs)),\n",
    "            np.zeros(1), 1\n",
    "        ])\n",
    "        self.num_epochs = num_epochs\n",
    "        self.regularization_weight = regularization_weight\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            np.random.shuffle(X)\n",
    "            np.random.shuffle(Y)\n",
    "            X_split = np.array_split(X, len(X) // self.batch_size)\n",
    "            Y_split = np.array_split(Y, len(Y) // self.batch_size)\n",
    "            for ind in range(len(X_split)):\n",
    "                X_batch, Y_batch = X_split[ind], Y_split[ind]\n",
    "                grad_weights = []\n",
    "                grad_biases = []\n",
    "                loss = 0\n",
    "                for layer in self.hidden_layers:\n",
    "                    grad_weights.append(np.zeros_like(layer[0]))\n",
    "                    grad_biases.append(np.zeros_like(layer[1]))\n",
    "                for t in range(len(X_batch)):\n",
    "                    single_X = X_batch[t]\n",
    "                    single_Y = Y_batch[t]\n",
    "                    #                     print(\"sing_x is \" ,single_X, \" and sing y is \",single_Y)\n",
    "                    #                     print(\"sh_x is \" ,single_X.shape, \" and sh y is \",single_Y.shape)\n",
    "\n",
    "                    # forward pass saving all activation outputs\n",
    "                    activations = []\n",
    "                    temp = single_X\n",
    "                    for layer in self.hidden_layers:\n",
    "                        lin = np.matmul(layer[0], temp) + layer[1]\n",
    "                        act = sigmoid(lin)\n",
    "                        activations.append(act)\n",
    "                        temp = act\n",
    "\n",
    "                    pred_prob = activations[-1]\n",
    "                    #                     print(\"my pred prob is  \",pred_prob, \" and correct is \", single_Y)\n",
    "                    #                     print(\"-----------------------  \")\n",
    "                    delta_loss = -(single_Y * np.log(pred_prob) +\n",
    "                                   (1 - single_Y) * np.log(1 - pred_prob))\n",
    "                    loss += delta_loss\n",
    "                    # backward pass saving all error terms\n",
    "                    errors = []\n",
    "                    # opposite order ie last error term first\n",
    "\n",
    "                    initial_error = (pred_prob - single_Y)\n",
    "\n",
    "                    errors.append(initial_error)\n",
    "\n",
    "                    for i in range(len(self.hidden_layers) - 1, 0, -1):\n",
    "                        # all except last\n",
    "                        layer = self.hidden_layers[i]\n",
    "                        prev_error = errors[-1]\n",
    "                        newerror = np.multiply(\n",
    "                            np.dot(layer[0].T, prev_error),\n",
    "                            activations[i - 1] * (1 - activations[i - 1]))\n",
    "                        errors.append(newerror)\n",
    "                    errors = errors[::-1]\n",
    "                    for i in range(0, len(self.hidden_layers)):\n",
    "                        if i == 0:\n",
    "                            grad_weights[i] += np.matmul(\n",
    "                                errors[i][:, np.newaxis],\n",
    "                                single_X[:, np.newaxis].T)\n",
    "                            grad_biases[i] += errors[i]\n",
    "                        else:\n",
    "                            # actually error[i] is next term's error since\n",
    "                            # we don't add last term to error array\n",
    "                            grad_weights[i] += np.matmul(\n",
    "                                errors[i][:, np.newaxis],\n",
    "                                activations[i - 1][:, np.newaxis].T)\n",
    "                            grad_biases[i] += errors[i]\n",
    "\n",
    "                    if epoch == 10 and random.random() < 0.02:\n",
    "                        print(\"sing_x is \", \" and sing y is \", single_Y)\n",
    "                        print(\"my pred prob is  \", pred_prob,\n",
    "                              \" and correct is \", single_Y)\n",
    "                        print(\"my loss is \", delta_loss)\n",
    "                loss = loss / self.batch_size\n",
    "                if random.random() < 0.005:\n",
    "                    print(\"Epoch: \", epoch, \"Batch:\", ind, \" Loss is \", loss)\n",
    "                for i in range(0, len(self.hidden_layers)):\n",
    "                    layer = self.hidden_layers[i]\n",
    "                    layer[0] = layer[0] - self.lr * (\n",
    "                        (1 / self.batch_size) * grad_weights[i] +\n",
    "                        self.regularization_weight * layer[0])\n",
    "                    layer[1] = layer[1] - self.lr * (\n",
    "                        (1 / self.batch_size) * grad_biases[i])\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for t in range(len(X)):\n",
    "            single_X = X[t]\n",
    "            #             activations = []\n",
    "            temp = single_X\n",
    "            for layer in self.hidden_layers:\n",
    "                lin = np.matmul(layer[0], temp) + layer[1]\n",
    "                act = sigmoid(lin)\n",
    "                #                 activations.append(act)\n",
    "                temp = act\n",
    "            pred.append(temp)\n",
    "        pred = np.squeeze(np.asarray(pred))\n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred < 0.5] = 0\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T14:41:21.104686Z",
     "start_time": "2018-04-10T14:41:21.092245Z"
    }
   },
   "outputs": [],
   "source": [
    "n = NeuralNetwork(3,[5],3,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:51:28.487141Z",
     "start_time": "2018-04-09T13:51:28.482257Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.asarray([[4],[8],[1],[9],[2],[5]])\n",
    "y = np.asarray([0,1,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:51:28.500821Z",
     "start_time": "2018-04-09T13:51:28.495063Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.asarray([[4,5,6],[8,3,1],[1,-6,3],[9,6,1],[2,1,1],[5,3,2]])\n",
    "y = np.asarray([1,1,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:51:28.556245Z",
     "start_time": "2018-04-09T13:51:28.503159Z"
    }
   },
   "outputs": [],
   "source": [
    "n.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:14.025299Z",
     "start_time": "2018-04-11T08:05:14.013873Z"
    }
   },
   "outputs": [],
   "source": [
    "n = NeuralNetwork(2,[50],5,num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:10.894521Z",
     "start_time": "2018-04-11T08:05:10.843202Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.genfromtxt(\"toy_data/toy_trainX.csv\",delimiter=\",\")\n",
    "y = np.genfromtxt(\"toy_data/toy_trainY.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"toy_data/toy_testX.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"toy_data/toy_testY.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:16.240540Z",
     "start_time": "2018-04-11T08:05:15.061394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Batch: 53  Loss is  [0.69911848]\n",
      "Epoch:  6 Batch: 49  Loss is  [0.76161086]\n",
      "Epoch:  7 Batch: 56  Loss is  [1.00557841]\n",
      "Epoch:  8 Batch: 49  Loss is  [0.58587047]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.54775817]  and correct is  1.0\n",
      "my loss is  [0.60192139]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.29841763]  and correct is  0.0\n",
      "my loss is  [0.35441696]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.34485242]  and correct is  1.0\n",
      "my loss is  [1.06463872]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.45035785]  and correct is  0.0\n",
      "my loss is  [0.59848786]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.4662161]  and correct is  0.0\n",
      "my loss is  [0.6277642]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.37229104]  and correct is  0.0\n",
      "my loss is  [0.46567866]\n",
      "Epoch:  12 Batch: 26  Loss is  [0.67538984]\n",
      "Epoch:  16 Batch: 12  Loss is  [0.66132133]\n",
      "Epoch:  19 Batch: 58  Loss is  [0.91121676]\n",
      "Epoch:  31 Batch: 61  Loss is  [0.72570612]\n",
      "Epoch:  33 Batch: 18  Loss is  [0.74400613]\n",
      "Epoch:  33 Batch: 28  Loss is  [0.76817072]\n",
      "Epoch:  33 Batch: 74  Loss is  [0.74400083]\n",
      "Epoch:  35 Batch: 4  Loss is  [0.80030768]\n",
      "Epoch:  40 Batch: 36  Loss is  [0.64614162]\n",
      "Epoch:  45 Batch: 50  Loss is  [0.7425055]\n"
     ]
    }
   ],
   "source": [
    "n.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:18.466571Z",
     "start_time": "2018-04-11T08:05:18.454366Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = n.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:19.687911Z",
     "start_time": "2018-04-11T08:05:19.480307Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:19.739533Z",
     "start_time": "2018-04-11T08:05:19.733915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44166666666666665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:51:30.630014Z",
     "start_time": "2018-04-09T13:51:30.626457Z"
    }
   },
   "outputs": [],
   "source": [
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:32.606369Z",
     "start_time": "2018-04-11T08:05:23.871516Z"
    }
   },
   "outputs": [],
   "source": [
    "dat_train = np.genfromtxt(\"mnist_data/MNIST_train.csv\",delimiter=\",\")\n",
    "dat_test = np.genfromtxt(\"mnist_data/MNIST_test.csv\",delimiter=\",\")\n",
    "np.random.shuffle(dat_test)\n",
    "np.random.shuffle(dat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:32.747876Z",
     "start_time": "2018-04-11T08:05:32.653904Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , Y_train = dat_train[:,:784], dat_train[:,784]\n",
    "X_test , Y_test = dat_test[:,:784], dat_test[:,784]\n",
    "\n",
    "# X_train , Y_train = dat[:7000,:784], dat[:7000,784]\n",
    "# X_test , Y_test = dat[7000:,:784], dat[7000:,784]\n",
    "\n",
    "X_train = (X_train/255)*2 - 1\n",
    "X_test = (X_test/255)*2 - 1\n",
    "\n",
    "Y_train[Y_train==6.] = 0\n",
    "Y_train[Y_train==8.] = 1\n",
    "\n",
    "Y_test[Y_test==6.] = 0\n",
    "Y_test[Y_test==8.] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:32.799511Z",
     "start_time": "2018-04-11T08:05:32.796221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:32.865408Z",
     "start_time": "2018-04-11T08:05:32.852297Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T15:21:54.888320Z",
     "start_time": "2018-04-10T15:21:26.006719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17032465\n",
      "Iteration 2, loss = 0.04824293\n",
      "Iteration 3, loss = 0.04021634\n",
      "Iteration 4, loss = 0.03628389\n",
      "Iteration 5, loss = 0.03324991\n",
      "Iteration 6, loss = 0.03187019\n",
      "Iteration 7, loss = 0.02977471\n",
      "Iteration 8, loss = 0.02868009\n",
      "Iteration 9, loss = 0.02786391\n",
      "Iteration 10, loss = 0.02687830\n",
      "Iteration 11, loss = 0.02590574\n",
      "Iteration 12, loss = 0.02491049\n",
      "Iteration 13, loss = 0.02412223\n",
      "Iteration 14, loss = 0.02319702\n",
      "Iteration 15, loss = 0.02359437\n",
      "Iteration 16, loss = 0.02189902\n",
      "Iteration 17, loss = 0.02175430\n",
      "Iteration 18, loss = 0.02172335\n",
      "Iteration 19, loss = 0.02105438\n",
      "Iteration 20, loss = 0.02048204\n",
      "Iteration 21, loss = 0.02014162\n",
      "Iteration 22, loss = 0.01925187\n",
      "Iteration 23, loss = 0.01938837\n",
      "Iteration 24, loss = 0.01871620\n",
      "Iteration 25, loss = 0.01849062\n",
      "Iteration 26, loss = 0.01791861\n",
      "Iteration 27, loss = 0.01727691\n",
      "Iteration 28, loss = 0.01695515\n",
      "Iteration 29, loss = 0.01706616\n",
      "Iteration 30, loss = 0.01684688\n",
      "Iteration 31, loss = 0.01628138\n",
      "Iteration 32, loss = 0.01553054\n",
      "Iteration 33, loss = 0.01557322\n",
      "Iteration 34, loss = 0.01551853\n",
      "Iteration 35, loss = 0.01499665\n",
      "Iteration 36, loss = 0.01466707\n",
      "Iteration 37, loss = 0.01447767\n",
      "Iteration 38, loss = 0.01447133\n",
      "Iteration 39, loss = 0.01364987\n",
      "Iteration 40, loss = 0.01362971\n",
      "Iteration 41, loss = 0.01358088\n",
      "Iteration 42, loss = 0.01272273\n",
      "Iteration 43, loss = 0.01279538\n",
      "Iteration 44, loss = 0.01242537\n",
      "Iteration 45, loss = 0.01238322\n",
      "Iteration 46, loss = 0.01206599\n",
      "Iteration 47, loss = 0.01145392\n",
      "Iteration 48, loss = 0.01110257\n",
      "Iteration 49, loss = 0.01085072\n",
      "Iteration 50, loss = 0.01070584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madhur/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9925"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',\n",
    "                    solver='sgd',learning_rate_init=0.01,max_iter=10,batch_size=50,verbose=True,tol=1e-5)\n",
    "clf.fit(X_train,Y_train)\n",
    "skpred = clf.predict(X_test)\n",
    "accuracy_score(Y_test,skpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:05:32.938786Z",
     "start_time": "2018-04-11T08:05:32.930702Z"
    }
   },
   "outputs": [],
   "source": [
    "mneural = NeuralNetwork(784,[100],50,num_epochs=12,lr=0.01,regularization_weight=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:06:15.053994Z",
     "start_time": "2018-04-11T08:05:33.013047Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch: 88  Loss is  [1.73484295]\n",
      "Epoch:  1 Batch: 112  Loss is  [2.28176271]\n",
      "Epoch:  1 Batch: 183  Loss is  [2.94109209]\n",
      "Epoch:  2 Batch: 1  Loss is  [1.67245009]\n",
      "Epoch:  2 Batch: 40  Loss is  [2.9540717]\n",
      "Epoch:  2 Batch: 43  Loss is  [2.33609525]\n",
      "Epoch:  2 Batch: 82  Loss is  [2.77288287]\n",
      "Epoch:  2 Batch: 140  Loss is  [1.6507498]\n",
      "Epoch:  3 Batch: 44  Loss is  [1.56862205]\n",
      "Epoch:  3 Batch: 107  Loss is  [2.25258079]\n",
      "Epoch:  4 Batch: 11  Loss is  [2.84572677]\n",
      "Epoch:  4 Batch: 147  Loss is  [2.00638735]\n",
      "Epoch:  5 Batch: 57  Loss is  [2.13020329]\n",
      "Epoch:  5 Batch: 78  Loss is  [2.42497202]\n",
      "Epoch:  7 Batch: 180  Loss is  [1.96727817]\n",
      "Epoch:  9 Batch: 102  Loss is  [1.33388154]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01653771]  and correct is  0.0\n",
      "my loss is  [0.01667598]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.03621175]  and correct is  0.0\n",
      "my loss is  [0.03688366]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.02666359]  and correct is  0.0\n",
      "my loss is  [0.02702551]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00066735]  and correct is  0.0\n",
      "my loss is  [0.00066758]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.07148147]  and correct is  0.0\n",
      "my loss is  [0.07416495]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.06620854]  and correct is  1.0\n",
      "my loss is  [2.71494579]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0048072]  and correct is  1.0\n",
      "my loss is  [5.33764044]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00023313]  and correct is  0.0\n",
      "my loss is  [0.00023316]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.15891319]  and correct is  1.0\n",
      "my loss is  [1.83939721]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02038646]  and correct is  1.0\n",
      "my loss is  [3.89288418]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.38293677]  and correct is  0.0\n",
      "my loss is  [0.48278377]\n",
      "Epoch:  10 Batch: 13  Loss is  [1.65685999]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00151998]  and correct is  0.0\n",
      "my loss is  [0.00152113]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.16541746]  and correct is  1.0\n",
      "my loss is  [1.79928292]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00490831]  and correct is  1.0\n",
      "my loss is  [5.31682469]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00216121]  and correct is  1.0\n",
      "my loss is  [6.13708501]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0340209]  and correct is  0.0\n",
      "my loss is  [0.03461308]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00277776]  and correct is  0.0\n",
      "my loss is  [0.00278163]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.11808526]  and correct is  1.0\n",
      "my loss is  [2.13634836]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01542871]  and correct is  1.0\n",
      "my loss is  [4.17152493]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.64322672]  and correct is  0.0\n",
      "my loss is  [1.03065476]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.3920047]  and correct is  0.0\n",
      "my loss is  [0.49758813]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.10825809]  and correct is  1.0\n",
      "my loss is  [2.22323718]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01409288]  and correct is  0.0\n",
      "my loss is  [0.01419313]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.18170796]  and correct is  1.0\n",
      "my loss is  [1.70535449]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00267303]  and correct is  0.0\n",
      "my loss is  [0.00267661]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00099431]  and correct is  0.0\n",
      "my loss is  [0.0009948]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.09091804]  and correct is  1.0\n",
      "my loss is  [2.39779679]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00671341]  and correct is  1.0\n",
      "my loss is  [5.00364799]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00260703]  and correct is  1.0\n",
      "my loss is  [5.94954397]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00130031]  and correct is  1.0\n",
      "my loss is  [6.64515582]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.7362435]  and correct is  0.0\n",
      "my loss is  [1.33272896]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00148168]  and correct is  1.0\n",
      "my loss is  [6.51457645]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.08968811]  and correct is  0.0\n",
      "my loss is  [0.093968]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.94051874]  and correct is  1.0\n",
      "my loss is  [0.0613237]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.45370272]  and correct is  0.0\n",
      "my loss is  [0.60459198]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01430407]  and correct is  0.0\n",
      "my loss is  [0.01440736]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00060597]  and correct is  1.0\n",
      "my loss is  [7.40868213]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.28001375]  and correct is  0.0\n",
      "my loss is  [0.32852316]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.17635443]  and correct is  1.0\n",
      "my loss is  [1.73525947]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00828242]  and correct is  1.0\n",
      "my loss is  [4.79362051]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00845875]  and correct is  0.0\n",
      "my loss is  [0.00849473]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.05399272]  and correct is  0.0\n",
      "my loss is  [0.05550502]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.02038551]  and correct is  0.0\n",
      "my loss is  [0.02059616]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00583378]  and correct is  0.0\n",
      "my loss is  [0.00585086]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.04233171]  and correct is  0.0\n",
      "my loss is  [0.04325381]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00952169]  and correct is  0.0\n",
      "my loss is  [0.00956731]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.06173492]  and correct is  0.0\n",
      "my loss is  [0.06372277]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.20490747]  and correct is  0.0\n",
      "my loss is  [0.22929678]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.16857818]  and correct is  1.0\n",
      "my loss is  [1.78035566]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [1.4904882e-05]  and correct is  0.0\n",
      "my loss is  [1.49049931e-05]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00215927]  and correct is  1.0\n",
      "my loss is  [6.13798689]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.09832777]  and correct is  0.0\n",
      "my loss is  [0.10350421]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00163752]  and correct is  0.0\n",
      "my loss is  [0.00163886]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.12796912]  and correct is  1.0\n",
      "my loss is  [2.05596632]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [1.05371716e-05]  and correct is  0.0\n",
      "my loss is  [1.05372271e-05]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.22539808]  and correct is  0.0\n",
      "my loss is  [0.25540603]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00201762]  and correct is  1.0\n",
      "my loss is  [6.20583691]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.15468]  and correct is  0.0\n",
      "my loss is  [0.16804002]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.09602072]  and correct is  0.0\n",
      "my loss is  [0.10094884]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00655346]  and correct is  1.0\n",
      "my loss is  [5.02776271]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.1889228]  and correct is  0.0\n",
      "my loss is  [0.20939204]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.08718739]  and correct is  0.0\n",
      "my loss is  [0.09122467]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00098085]  and correct is  1.0\n",
      "my loss is  [6.92709162]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01015573]  and correct is  0.0\n",
      "my loss is  [0.01020765]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0223585]  and correct is  0.0\n",
      "my loss is  [0.02261224]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.07818269]  and correct is  0.0\n",
      "my loss is  [0.08140822]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.10904573]  and correct is  0.0\n",
      "my loss is  [0.11546218]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.83185446]  and correct is  1.0\n",
      "my loss is  [0.18409778]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00026716]  and correct is  0.0\n",
      "my loss is  [0.0002672]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.09497864]  and correct is  1.0\n",
      "my loss is  [2.35410324]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00735307]  and correct is  1.0\n",
      "my loss is  [4.9126369]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.15780825]  and correct is  1.0\n",
      "my loss is  [1.84637462]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00219749]  and correct is  0.0\n",
      "my loss is  [0.0021999]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00064728]  and correct is  0.0\n",
      "my loss is  [0.00064749]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01851914]  and correct is  1.0\n",
      "my loss is  [3.98895045]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00136956]  and correct is  1.0\n",
      "my loss is  [6.59326589]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.06111275]  and correct is  0.0\n",
      "my loss is  [0.06305988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00090078]  and correct is  0.0\n",
      "my loss is  [0.00090119]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00587879]  and correct is  1.0\n",
      "my loss is  [5.13640506]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0137606]  and correct is  1.0\n",
      "my loss is  [4.28594553]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.25278688]  and correct is  0.0\n",
      "my loss is  [0.29140484]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.02684271]  and correct is  0.0\n",
      "my loss is  [0.02720956]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0570362]  and correct is  0.0\n",
      "my loss is  [0.05872738]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01215691]  and correct is  1.0\n",
      "my loss is  [4.40985735]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.19566849]  and correct is  1.0\n",
      "my loss is  [1.63133341]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.92410837]  and correct is  1.0\n",
      "my loss is  [0.07892593]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.16206339]  and correct is  0.0\n",
      "my loss is  [0.17681283]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.08130811]  and correct is  0.0\n",
      "my loss is  [0.08480448]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.51978141]  and correct is  1.0\n",
      "my loss is  [0.65434692]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.22458193]  and correct is  1.0\n",
      "my loss is  [1.49351467]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00147164]  and correct is  1.0\n",
      "my loss is  [6.52137759]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.21624973]  and correct is  1.0\n",
      "my loss is  [1.53132136]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.67222829]  and correct is  0.0\n",
      "my loss is  [1.11543792]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.11434964]  and correct is  1.0\n",
      "my loss is  [2.16849454]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0271752]  and correct is  0.0\n",
      "my loss is  [0.02755128]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.72089366]  and correct is  0.0\n",
      "my loss is  [1.27616243]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.08633324]  and correct is  1.0\n",
      "my loss is  [2.44954063]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.37976458]  and correct is  1.0\n",
      "my loss is  [0.96820374]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.25224082]  and correct is  1.0\n",
      "my loss is  [1.37737102]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.08232492]  and correct is  1.0\n",
      "my loss is  [2.49708146]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01556625]  and correct is  1.0\n",
      "my loss is  [4.1626504]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0523829]  and correct is  1.0\n",
      "my loss is  [2.94917502]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.64163425]  and correct is  0.0\n",
      "my loss is  [1.02620117]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.27322671]  and correct is  0.0\n",
      "my loss is  [0.31914069]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.05301772]  and correct is  0.0\n",
      "my loss is  [0.05447489]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02386958]  and correct is  1.0\n",
      "my loss is  [3.73515063]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00203032]  and correct is  1.0\n",
      "my loss is  [6.19955984]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.03942314]  and correct is  0.0\n",
      "my loss is  [0.04022128]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.25099639]  and correct is  1.0\n",
      "my loss is  [1.38231673]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00564042]  and correct is  0.0\n",
      "my loss is  [0.00565639]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.02206407]  and correct is  0.0\n",
      "my loss is  [0.02231112]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.72018347]  and correct is  1.0\n",
      "my loss is  [0.32824928]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.22267011]  and correct is  0.0\n",
      "my loss is  [0.25189045]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.06959298]  and correct is  0.0\n",
      "my loss is  [0.07213313]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00099773]  and correct is  1.0\n",
      "my loss is  [6.91002916]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.28203539]  and correct is  1.0\n",
      "my loss is  [1.26572273]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.23504436]  and correct is  0.0\n",
      "my loss is  [0.26793743]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.90220243]  and correct is  0.0\n",
      "my loss is  [2.32485557]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01499961]  and correct is  0.0\n",
      "my loss is  [0.01511324]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.53664099]  and correct is  1.0\n",
      "my loss is  [0.62242595]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.09140336]  and correct is  0.0\n",
      "my loss is  [0.09585403]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.49290835]  and correct is  0.0\n",
      "my loss is  [0.67906353]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.05302659]  and correct is  1.0\n",
      "my loss is  [2.93696181]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02280295]  and correct is  1.0\n",
      "my loss is  [3.7808654]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00660754]  and correct is  1.0\n",
      "my loss is  [5.01954402]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.21240167]  and correct is  1.0\n",
      "my loss is  [1.54927614]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0031481]  and correct is  0.0\n",
      "my loss is  [0.00315307]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.04887727]  and correct is  0.0\n",
      "my loss is  [0.05011217]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01426695]  and correct is  0.0\n",
      "my loss is  [0.0143697]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.4534797]  and correct is  0.0\n",
      "my loss is  [0.60418383]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.06100851]  and correct is  0.0\n",
      "my loss is  [0.06294887]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00290664]  and correct is  1.0\n",
      "my loss is  [5.84075727]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [7.42936323e-05]  and correct is  0.0\n",
      "my loss is  [7.42963922e-05]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01678428]  and correct is  0.0\n",
      "my loss is  [0.01692673]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.68874287]  and correct is  0.0\n",
      "my loss is  [1.16713592]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.68561463]  and correct is  0.0\n",
      "my loss is  [1.15713575]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.84633285]  and correct is  0.0\n",
      "my loss is  [1.87296636]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.05369963]  and correct is  1.0\n",
      "my loss is  [2.92434913]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.66118635]  and correct is  1.0\n",
      "my loss is  [0.41371956]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.12532664]  and correct is  1.0\n",
      "my loss is  [2.07683186]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01876796]  and correct is  1.0\n",
      "my loss is  [3.97560425]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.03577879]  and correct is  1.0\n",
      "my loss is  [3.33040015]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.07869252]  and correct is  0.0\n",
      "my loss is  [0.08196145]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.05504206]  and correct is  1.0\n",
      "my loss is  [2.8996577]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.13553559]  and correct is  0.0\n",
      "my loss is  [0.14564514]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00129639]  and correct is  0.0\n",
      "my loss is  [0.00129723]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.03478073]  and correct is  1.0\n",
      "my loss is  [3.35869186]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.79279776]  and correct is  0.0\n",
      "my loss is  [1.57405996]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01699779]  and correct is  0.0\n",
      "my loss is  [0.01714391]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00403124]  and correct is  1.0\n",
      "my loss is  [5.51368235]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.84286934]  and correct is  0.0\n",
      "my loss is  [1.8506776]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.01280766]  and correct is  0.0\n",
      "my loss is  [0.01289038]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0617556]  and correct is  0.0\n",
      "my loss is  [0.06374481]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.07918857]  and correct is  0.0\n",
      "my loss is  [0.08250001]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [3.00479584e-06]  and correct is  1.0\n",
      "my loss is  [12.71530093]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.07214052]  and correct is  1.0\n",
      "my loss is  [2.62913938]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.12269868]  and correct is  0.0\n",
      "my loss is  [0.13090477]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.58227337]  and correct is  1.0\n",
      "my loss is  [0.54081524]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0219582]  and correct is  1.0\n",
      "my loss is  [3.81861464]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.3196594]  and correct is  1.0\n",
      "my loss is  [1.14049921]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.08032571]  and correct is  0.0\n",
      "my loss is  [0.0837357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.11690629]  and correct is  1.0\n",
      "my loss is  [2.14638264]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.09564038]  and correct is  0.0\n",
      "my loss is  [0.10052818]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0115642]  and correct is  1.0\n",
      "my loss is  [4.45984118]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.18955818]  and correct is  0.0\n",
      "my loss is  [0.21017573]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02629257]  and correct is  1.0\n",
      "my loss is  [3.63846893]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.17018468]  and correct is  0.0\n",
      "my loss is  [0.18655211]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00190536]  and correct is  0.0\n",
      "my loss is  [0.00190718]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0144051]  and correct is  1.0\n",
      "my loss is  [4.24017318]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01508061]  and correct is  1.0\n",
      "my loss is  [4.1943457]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02293764]  and correct is  1.0\n",
      "my loss is  [3.77497607]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.03589902]  and correct is  0.0\n",
      "my loss is  [0.03655924]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.03485496]  and correct is  0.0\n",
      "my loss is  [0.03547689]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.0004019]  and correct is  1.0\n",
      "my loss is  [7.81929718]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.03940753]  and correct is  0.0\n",
      "my loss is  [0.04020503]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01121771]  and correct is  1.0\n",
      "my loss is  [4.49026174]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02938274]  and correct is  1.0\n",
      "my loss is  [3.52734779]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.57426354]  and correct is  1.0\n",
      "my loss is  [0.55466686]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.67065575]  and correct is  0.0\n",
      "my loss is  [1.11065173]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.14559601]  and correct is  1.0\n",
      "my loss is  [1.92691957]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.04622403]  and correct is  1.0\n",
      "my loss is  [3.07425548]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [3.83758278e-05]  and correct is  1.0\n",
      "my loss is  [10.16808278]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.86460855]  and correct is  1.0\n",
      "my loss is  [0.14547842]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00112133]  and correct is  1.0\n",
      "my loss is  [6.79324413]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.05425555]  and correct is  1.0\n",
      "my loss is  [2.91404995]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.2681968]  and correct is  1.0\n",
      "my loss is  [1.31603423]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00419512]  and correct is  0.0\n",
      "my loss is  [0.00420395]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.24201027]  and correct is  1.0\n",
      "my loss is  [1.41877513]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00439559]  and correct is  0.0\n",
      "my loss is  [0.00440528]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.0041074]  and correct is  0.0\n",
      "my loss is  [0.00411586]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00349126]  and correct is  0.0\n",
      "my loss is  [0.00349737]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.66761517]  and correct is  0.0\n",
      "my loss is  [1.10146186]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.63279853]  and correct is  0.0\n",
      "my loss is  [1.00184463]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.69790008]  and correct is  1.0\n",
      "my loss is  [0.35967934]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.01152706]  and correct is  1.0\n",
      "my loss is  [4.46305788]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.04246309]  and correct is  0.0\n",
      "my loss is  [0.04339101]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.98853234]  and correct is  0.0\n",
      "my loss is  [4.46822471]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.26984938]  and correct is  0.0\n",
      "my loss is  [0.31450444]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.07263593]  and correct is  0.0\n",
      "my loss is  [0.07540905]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.02559176]  and correct is  1.0\n",
      "my loss is  [3.66548501]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.00284458]  and correct is  1.0\n",
      "my loss is  [5.86233843]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.69459174]  and correct is  0.0\n",
      "my loss is  [1.18610583]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.21782353]  and correct is  0.0\n",
      "my loss is  [0.2456749]\n",
      "sing_x is   and sing y is  1.0\n",
      "my pred prob is   [0.11082522]  and correct is  1.0\n",
      "my loss is  [2.19980092]\n",
      "sing_x is   and sing y is  0.0\n",
      "my pred prob is   [0.00137429]  and correct is  0.0\n",
      "my loss is  [0.00137524]\n",
      "Epoch:  11 Batch: 169  Loss is  [1.78719075]\n"
     ]
    }
   ],
   "source": [
    "mneural.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T15:30:29.633024Z",
     "start_time": "2018-04-10T15:30:29.622697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.59070437, -0.34521   ,  0.10131911,  0.48699577, -1.62590326,\n",
       "          0.22310992, -1.35544323,  0.42766163, -0.66695379,  0.27387383,\n",
       "          0.82328754, -0.68483697,  0.41131478, -0.08793164, -0.68635511,\n",
       "         -0.48826139,  0.03812553, -0.72650182,  0.03037515, -1.79740283,\n",
       "         -0.43524056, -1.13530616, -1.45725119, -0.7226563 , -0.09407695,\n",
       "         -0.92940445,  0.55709702, -1.17107694,  0.49172552,  0.06764196,\n",
       "         -0.50155474, -1.61439232,  1.07624619,  0.96581565, -0.09704489,\n",
       "          2.28264107, -1.3459737 ,  1.2935223 , -1.06453892, -0.74336102,\n",
       "          0.28513513,  0.65278384,  0.27903803, -1.19550068,  0.67246312,\n",
       "          0.16122182,  0.02952448, -0.15808203,  0.61681644,  0.45716827,\n",
       "         -0.81415391,  0.80256289, -0.47574415, -0.45641441, -1.11863676,\n",
       "          0.51151816, -0.00750102,  0.16152751,  0.02172961,  0.39666591,\n",
       "         -0.26256963,  0.27927701, -0.14956441,  0.94722938,  1.14181699,\n",
       "         -0.18223214, -1.12205035, -0.75827712,  0.77665888,  0.24147016,\n",
       "         -1.4629976 ,  0.96828831, -0.57008401,  0.28343142,  1.21351006,\n",
       "          0.39653484, -0.61360648, -0.0103384 ,  0.10492627, -1.53167111,\n",
       "         -0.37751855,  0.15901525,  0.26036894,  0.34890554, -0.82758701,\n",
       "          0.23258005,  1.56540855, -0.24536036,  0.66715267, -0.46394267,\n",
       "          0.26628414,  1.04660265, -0.03479921,  0.82415823,  0.14571754,\n",
       "          0.39191922,  0.46046989,  1.30945463,  0.68595127, -0.17517662]]),\n",
       " array([-0.08470861]),\n",
       " 1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mneural.hidden_layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T14:27:13.166685Z",
     "start_time": "2018-04-09T14:27:12.857209Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = mneural.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T14:27:13.266583Z",
     "start_time": "2018-04-09T14:27:13.248337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T14:14:10.441796Z",
     "start_time": "2018-04-09T14:14:10.434972Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T08:11:59.832195Z",
     "start_time": "2018-04-09T08:11:59.807053Z"
    }
   },
   "outputs": [],
   "source": [
    "list(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T20:18:25.113868Z",
     "start_time": "2018-04-05T20:18:25.109154Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T19:36:00.559253Z",
     "start_time": "2018-04-05T19:36:00.550840Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T19:24:01.002074Z",
     "start_time": "2018-04-05T19:24:00.996365Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.asarray([1,2,3,4,5])\n",
    "arr2 = np.asarray([1,-10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T19:25:45.081494Z",
     "start_time": "2018-04-05T19:25:45.076010Z"
    }
   },
   "outputs": [],
   "source": [
    "arr[:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T19:25:20.413050Z",
     "start_time": "2018-04-05T19:25:20.404543Z"
    }
   },
   "outputs": [],
   "source": [
    "np.dot(arr[:,np.newaxis],arr2[:,np.newaxis].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T18:44:50.919825Z",
     "start_time": "2018-04-05T18:44:50.915071Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(arr) - 1, 0, -1):\n",
    "    print(arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "866px",
    "right": "64px",
    "top": "107px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
